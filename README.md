# PartialWaveAnalysis

Usage: This repo contains all the code I use to perform a partial wave analysis using the AmpTools software provided by IU at GlueX. To utilize this software, you must already have access to the [halld_sim](https://github.com/JeffersonLab/halld_sim) suite of programs, since this code calls upon `FitResults.h` and `fit.C` from the AmpTools library and `split_mass`. You also need access to the [gluex_root_analysis](https://github.com/JeffersonLab/gluex_root_analysis) program [`tree_to_amptools`](https://github.com/JeffersonLab/gluex_root_analysis/tree/master/programs/tree_to_amptools).

1. Run `tree_to_amptools` on MC Thrown, MC Reconstructed, Data, and (optional) Background ROOT TTrees.
  1. Basic syntax is `$ tree_to_amptools <input ROOT file name> <name of TTree in that file> (optional) -w <double, set weight for all events in tree>` for all but the Thrown trees
  2. For MC Thrown trees, you need to also include `-gen <Particle_t> <Particle_t> <...>` with particle ID numbers (see [particleType.h](https://github.com/JeffersonLab/halld_recon/blob/master/src/libraries/include/particleType.h) for a complete list of options) corresponding to the final states in the Thrown tree in the order they were generated.
  3. When I run my code, all trees except the thrown tree have three final state particles, a recoil proton and two decaying K_Shorts. For the Thrown tree, I add `-gen 14 9 8 9 8` since the final state which is generated by the Monte Carlo is `Proton, PiMinus1, PiPlus1, PiMinus2, PiPlus2`. I'm pretty sure the Thrown tree is only used for acceptence corrections later on, so when we split this up by mass bins, there shouldn't be any problems since it just interprets the final state mass as the sum of all the particles except for the recoil proton (and the beam) -- this was somewhere in the documentation for `split_mass`.
  4. Each time you run `tree_to_amptools`, the file which it outputs will have the same name, no matter what input you provide. Therefore, you have to rename the output file before moving on to the next ROOT file.
2. Run `divide_data.py` provided by this repo. Running it without arguments will show a help string with the required arguments and a short description of their usage. This program essentially wraps the `split_mass` program across the AmpTools trees you just generated.
  1. I have included an [example config template file](https://github.com/denehoffman/PartialWaveAnalysis/blob/main/zlm_ksks.cfg) with some Zlm amplitudes and some tagged areas which get replaced by this program. The tags are also mentioned in the help message, but essentially just get replaced to set proper paths. Look in the example for the fields preceeded by `@` symbols.
  2. I haven't come up with a good way to do this yet, but this code currently only works with Zlm amplitudes which must be written in pairs of real (Re) and imaginary (Im) parts (as in the config file). The `get_fit_results` program used later will receive a list of waves found in that file by `run_amptools.py` which will be in the order they are written in the config file.
4. Run `run_amptools.py` to actually perform the fits with `fit.C`. Again, running without arguments will display the help message.
  1. The `-p <integer>` option will allow you to specify how many multiprocessing processes to generate. This is limited by the number of cores you have available. Python unfortunately does not support multithreading due to the Python Interpreter Lock, but generally my fits haven't taken very long (31 bins with 20 iterations took about 7 minutes the last time I ran it). Don't worry about not knowing how many cores you have, this option is more to limit the number used if you do know it, otherwise, just don't use this flag and the program will generate up to 60 processes.
  2. Additionally, the `-s <integer>` option allows you to set the seed (default is `seed = 1`). The seed is used to randomly generate starting parameter values to be used for the fit. In theory, if you use the same seed and the same number of bins and iterations, all of those generated values should be consistent across each run, as long as you aren't adding new parameters to your fits.
  3. `run_amptools.py` will also call `get_fit_results`. However, if you just downloaded this repo, you need to build `get_fit_results` by going into that directory and running the command `make`. You might (probably will) get some errors about directories not existing. After creating the directories as suggested, the compilation worked. There is probably a better way to do this, but I just copied the Makefile from Naomi Jarvis, and I don't actually know how it works.
5. If you've gotten to this step, you will now have an output directory that contains bin folders as well as a file titled `bin_info.txt` and one titled `fit_results.txt`. These are human-readable tab-separated files, so feel free to look inside them and see how they are structured. I wrote a quick script called `plot_results.py` to do some preliminary graphing, but it is very much a work-in-progress.

### TODO:
1. Need to implement polarization in this analysis
2. Need a better way of sending the proper waves in pairs to `get_fit_results` than just hoping the user writes them in a nice order
3. `plot_results.py` needs to be more robust and versatile. I want to be able to get separate subplots for each wave, but I want it to look nice also. I also want this program to have some command-line options to specify which waves to plot (or other things to plot)
4. `get_fit_results`
  1. This program needs to be expanded to include more information about the fits, such as phases between waves and the base amplitudes from the fit. Currently none of this code is suited to do any SDMEs, but eventually some separate programs should be added to handle these too.
  2. I should eventually try to implement a way to drop specific waves from the analysis. It might be easier to implement this in `run_amptools.py`.
